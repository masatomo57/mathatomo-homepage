---
image: ""
title: "YouTubeの視聴履歴から自分の好みを分析してみた"
date: "2024/08/26"
tag: ["Python"]
description: "YouTubeの視聴履歴データをPythonとMeCabを使って形態素解析し、頻出単語TOP100から自分の興味・好みを分析してみた記事。"
---

## はじめに

このサイトを作った時に、さすがに記事0はないな…と思ったので何か作ることにしました（と言いつつ、2ヶ月以上放置しています）。
自分は趣味が多い（方だと思っている）のですが、結局自分は何が好きなんだと言うことが気になったのでYouTubeの視聴履歴から頻出単語TOP100を見てみようと思います。


## 視聴履歴の取得

以下のサイトを参考に取得しました。

[YouTubeの視聴履歴を振り返ってみよう ～あなたはどのようにしてぽこピーにハマったのか？～](https://note.com/cachu_don/n/n976502e18345)


## 分析の準備

上記の記事で[Google Colaboratory](https://www.google.com/search?q=google+colaboratory&oq=&gs_lcrp=EgZjaHJvbWUqCQgAECMYJxjqAjIJCAAQIxgnGOoCMgkIARAjGCcY6gIyCQgCECMYJxjqAjIJCAMQIxgnGOoCMgkIBBAjGCcY6gIyCQgFECMYJxjqAjIJCAYQIxgnGOoCMgkIBxAjGCcY6gLSAQg3MjdqMGoxNagCCLACAQ&sourceid=chrome&ie=UTF-8#:~:text=Colaboratory%20%E3%81%B8%E3%82%88%E3%81%86%E3%81%93%E3%81%9D,google.com%20%E2%80%BA%20...)を使っていたので、なんとなく自分もそうしました。

ノートブックを新規作成し、取得したjsonファイルを置きます。pythonでデータ分析ということで、pandasを入れてjsonファイルを読み込みました。
全部見たいので、max_rowsをNoneにしています。
```
import pandas
import json

pandas.set_option('display.max_rows', None)
data = pandas.read_json("watch-history.json", encoding="utf-8")
```

データには余計な「 を視聴しました」という文言が入っていたので、取り除いておきます。
```
data['title'] = data.title.str.rstrip(" を視聴しました").dropna()
```

これを`data['title']`で表示してみましょう。

```
0	社会人3年目やのに残業が多すぎるからA5ランクの焼肉行く
1	【12,000円課金】新キャラ引くまで無限にガチャ回します！【メガニケ】
2	Super Street Fighter 2X Turbo スパ2X 超級快打旋風 超級街霸...
3	生徒人気ゼロの生活指導
4	鹿島アントラーズ  Kashima Antlers 北海道コンサドーレ札幌 Hokkaid...
5	【衝撃】マックで使える超便利な裏技がこちらwww #マジック #魔法使い #ドッキリ
6	7月27日新曲公開🪞#鏡音リンレン #vocaloid
7	DJふぉいがウーバーを利用しなくなった理由【レペゼン切り抜き】
8	GOAT #mbappe #kylianmbappe #championsleague #b...
9	「阿鼻叫喚の夏祭り」自衛隊 第一空挺団についての雑学
10	🔥130万再生突破！！！感動の迷言集〜運命の再会〜【2ch感動スレ】#shorts
11	イチロー衰えない #イチロー #安打製造機 #振り子打法 #甲子園
12	ICE COLD FROM DROGBA
13	絶対に聞かれるこの質問はこうやって答える！
14	MBTI全16種類がいる飲み会
...
```
できましたね。「なんだこのラインナップ…」とも思いますが進みましょう。


## 単語を取り出す

文を単語に分ける操作のことを、自然言語処理の言葉で形態素解析というそうです。これはを自力でやるのは難しいので、オープンソースの形態素解析エンジン[Mecab](https://taku910.github.io/mecab/)を使っていきます。

まずはMecabとおまじないたちのインストール&import。正規表現を使うので、ついでにreもimportします。
```
# MeCabのインストール
!sudo apt-get install mecab libmecab-dev mecab-ipadic-utf8
# Pythonのバインディングをインストール
!pip install mecab-python3
# 辞書
!pip install ipadic

import MeCab
import ipadic
import re
```

dataの中にはurlや数字、記号など余計なものが入っているので、それらを取り除く関数を定義します。
```
def preprocess_text(text):
    text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.MULTILINE)
    text = re.sub(r'\d+', '', text)
    text = re.sub(r'[^\w\s]', '', text)
    return text
```

以上を使って、出てくる単語たちを数えていきます。
```
nouns = []
for title in data['title']:
  cleaned_title = preprocess_text(title)
  node = mecab.parseToNode(cleaned_title)
  while node:
      if node.feature.startswith('名詞'):
          nouns.append(node.surface)
      node = node.next

word_count = Counter(nouns)
```
word_countに、単語とその単語の出現回数の組が入っています。

## 完成、そして結果発表

以上でほぼ完成です。それでは、ランキングTOP10を表示しましょう。
```
most_common_words = pandas.DataFrame(word_count.most_common(10), columns=['単語', '出現回数'])
most_common_words
```
```
	単語	出現回数
0	shorts	8502
1	雑学	1888
2	人	1539
3	Shorts	1445
4	マリオ	1378
5	切り抜き	1275
6	サッカー	1212
7	ゲーム	1063
8	クラブ	953
9	さん	951
10	中	823
```

...shortsが一位という，なんとも言い難い結果でした．

## 参考文献
 - [YouTubeの視聴履歴を振り返ってみよう ～あなたはどのようにしてぽこピーにハマったのか？～](https://note.com/cachu_don/n/n976502e18345)
 - [PythonでMeCabを使う際のメモ](https://qiita.com/smiler5617/items/0744c256841875824ed2)
 - [形態素解析とは｜意味・活用例と日本語の自然言語処理ツールを紹介！](https://aismiley.co.jp/ai_news/nlp-morpho-analysis-japanese/)
 - [MeCab: Yet Another Part-of-Speech and Morphological Analyzer](https://taku910.github.io/mecab/)